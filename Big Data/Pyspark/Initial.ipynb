{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a00e293",
   "metadata": {},
   "source": [
    "### PySpark Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4fae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c55269ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b8dff5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kris</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adarsh</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  Age  Experience\n",
       "0    Shri   29           2\n",
       "1    Kris   22           3\n",
       "2  Adarsh   22           4"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "16f8d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1aecc2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5acac0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-KAQQLB1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practise</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2b399c62a50>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1e0f662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pySpark = spark.read.csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3bbd131e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ff2de220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|   _c0|_c1|       _c2|\n",
      "+------+---+----------+\n",
      "|  Name|Age|Experience|\n",
      "|  Shri| 29|         2|\n",
      "|  Kris| 22|         3|\n",
      "|Adarsh| 22|         4|\n",
      "+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pySpark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8639e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pySpark = spark.read.option('header', 'true').csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4d675fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  Name|Age|Experience|\n",
      "+------+---+----------+\n",
      "|  Shri| 29|         2|\n",
      "|  Kris| 22|         3|\n",
      "|Adarsh| 22|         4|\n",
      "+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pySpark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f2003f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pySpark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bbc2ddde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Name='Shri', Age='29', Experience='2')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pySpark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cecf68c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[Name: string, Age: string, Experience: string]>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Schema\n",
    "df_pySpark.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7499d8",
   "metadata": {},
   "source": [
    "### Pyspark DataFrames Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6a23b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here infer schema is used for the understanding of Data types becuase as you can observe above that \n",
    "# by default for all columns it was taking as String as datatype \n",
    "df_pySpark = spark.read.option('header', 'true').csv('data.csv', inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e21e8365",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pySpark = spark.read.csv('data.csv', header = True, inferSchema = True) # The other way of specifying the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "215acd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[Name: string, Age: int, Experience: int]>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pySpark.printSchema # As you can see now the age and experience as the type int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fad05c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pySpark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "90792ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Experience']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pySpark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2a17a484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Selecting a particular column\n",
    "\n",
    "df_pySpark.select('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6fe6d853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  Name|\n",
      "+------+\n",
      "|  Shri|\n",
      "|  Kris|\n",
      "|Adarsh|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pySpark.select('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "702c2c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: int]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting multiple columns\n",
    "\n",
    "df_pySpark.select(['Name', 'Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4032a66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  Name|Age|\n",
      "+------+---+\n",
      "|  Shri| 29|\n",
      "|  Kris| 22|\n",
      "|Adarsh| 22|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pySpark.select(['Name','Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "87838ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'int'), ('Experience', 'int')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pySpark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "68854c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Name: string, Age: string, Experience: string]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pySpark.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "232f20a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+----------+\n",
      "|summary|  Name|               Age|Experience|\n",
      "+-------+------+------------------+----------+\n",
      "|  count|     3|                 3|         3|\n",
      "|   mean|  NULL|24.333333333333332|       3.0|\n",
      "| stddev|  NULL| 4.041451884327381|       1.0|\n",
      "|    min|Adarsh|                22|         2|\n",
      "|    max|  Shri|                29|         4|\n",
      "+-------+------+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pySpark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a95c5951",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pySpark = df_pySpark.withColumn('Experience After 2 Years', df_pySpark['Experience']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1a104e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------------------------+\n",
      "|  Name|Age|Experience|Experience After 2 Years|\n",
      "+------+---+----------+------------------------+\n",
      "|  Shri| 29|         2|                       4|\n",
      "|  Kris| 22|         3|                       5|\n",
      "|Adarsh| 22|         4|                       6|\n",
      "+------+---+----------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pySpark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "632fe7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------------------------+\n",
      "|  Name|Age|Experience|Experience After 2 Years|\n",
      "+------+---+----------+------------------------+\n",
      "|  Shri| 29|         2|                       4|\n",
      "|  Kris| 22|         3|                       5|\n",
      "|Adarsh| 22|         4|                       6|\n",
      "+------+---+----------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# post reassigning the variable \n",
    "df_pySpark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cadf69b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pySpark = df_pySpark.drop('Experience After 2 Years') # Deleting a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "784d0fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  Name|Age|Experience|\n",
      "+------+---+----------+\n",
      "|  Shri| 29|         2|\n",
      "|  Kris| 22|         3|\n",
      "|Adarsh| 22|         4|\n",
      "+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pySpark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4bccc471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+\n",
      "|Username|Age|Experience|\n",
      "+--------+---+----------+\n",
      "|    Shri| 29|         2|\n",
      "|    Kris| 22|         3|\n",
      "|  Adarsh| 22|         4|\n",
      "+--------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pySpark.withColumnRenamed('Name','Username').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160ca3e2",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9af64fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2660970",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de37695",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('data.csv', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c88f4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| Age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|  Shri|  29|         2|  NULL|\n",
      "|  Kris|  22|         3| 12000|\n",
      "|Adarsh|  22|         4| 81000|\n",
      "| Anand|NULL|        12| 10101|\n",
      "|  NULL|  43|      NULL| 12243|\n",
      "|  NULL|  21|         4|  8425|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0671e1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Age: int, Experience: int, Salary: int]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f10d979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: int, Experience: int, Salary: int]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d495fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping NAN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f12ee91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Kris| 22|         3| 12000|\n",
      "|Adarsh| 22|         4| 81000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2c3de61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Age: int, Experience: int, Salary: int]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "744ca5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| Age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|  Shri|  29|         2|  NULL|\n",
      "|  Kris|  22|         3| 12000|\n",
      "|Adarsh|  22|         4| 81000|\n",
      "| Anand|NULL|        12| 10101|\n",
      "|  NULL|  43|      NULL| 12243|\n",
      "|  NULL|  21|         4|  8425|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9311a25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Kris| 22|         3| 12000|\n",
      "|Adarsh| 22|         4| 81000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how = \"any\").show() # Here it deletes a row if even one value is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1158dd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| Age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|  Shri|  29|         2|  NULL|\n",
      "|  Kris|  22|         3| 12000|\n",
      "|Adarsh|  22|         4| 81000|\n",
      "| Anand|NULL|        12| 10101|\n",
      "|  NULL|  43|      NULL| 12243|\n",
      "|  NULL|  21|         4|  8425|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how = \"all\").show() # Here it wont deletes a row even if a value is non null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c600c157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| Age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|  Shri|  29|         2|  NULL|\n",
      "|  Kris|  22|         3| 12000|\n",
      "|Adarsh|  22|         4| 81000|\n",
      "| Anand|NULL|        12| 10101|\n",
      "|  NULL|  21|         4|  8425|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Threshold values \n",
    "# Means setting a value to be checked for non value like\n",
    "# Atleast 'n' number of values should be non null\n",
    "\n",
    "df.na.drop(how = \"any\", thresh = 3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a221fe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Shri| 29|         2|  NULL|\n",
      "|  Kris| 22|         3| 12000|\n",
      "|Adarsh| 22|         4| 81000|\n",
      "|  NULL| 21|         4|  8425|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Subsetting\n",
    "# dropping the rows which are null in the specified column of subset\n",
    "df.na.drop(how = \"any\", subset = ['Age', 'Experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd3d1b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+\n",
      "|  Name| Age|Experience|Salary|\n",
      "+------+----+----------+------+\n",
      "|  Shri|  29|         2|  NULL|\n",
      "|  Kris|  22|         3| 12000|\n",
      "|Adarsh|  22|         4| 81000|\n",
      "| Anand|NULL|        12| 10101|\n",
      "|  NULL|  43|      NULL| 12243|\n",
      "|  NULL|  21|         4|  8425|\n",
      "+------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Filling the Missing Values\n",
    "# you can fill the values of na by following method like it takes\n",
    "# 2 paramets i.e.,(value, subset (optional - of type list))\n",
    "\n",
    "df.na.fill(\"Missing values\", [ 'Experience', 'Age' ]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58073cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols = ['Age', 'Experience', 'Salary'],\n",
    "    outputCols = [\"{}_imputed\".format(c) for c in ['Age', 'Experience', 'Salary']]\n",
    "    ).setStrategy(\"mode\")\n",
    "\n",
    "\n",
    "# Similarly you can try it for mode and median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afbc65c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+------+-----------+------------------+--------------+\n",
      "|  Name| Age|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+------+----+----------+------+-----------+------------------+--------------+\n",
      "|  Shri|  29|         2|  NULL|         29|                 2|          8425|\n",
      "|  Kris|  22|         3| 12000|         22|                 3|         12000|\n",
      "|Adarsh|  22|         4| 81000|         22|                 4|         81000|\n",
      "| Anand|NULL|        12| 10101|         22|                12|         10101|\n",
      "|  NULL|  43|      NULL| 12243|         43|                 4|         12243|\n",
      "|  NULL|  21|         4|  8425|         21|                 4|          8425|\n",
      "+------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add imputation cols to df\n",
    "\n",
    "imputer.fit(df).transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e096be",
   "metadata": {},
   "source": [
    "### Filter Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e47507db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('data.csv', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bf227c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|  Shri| 29|         2| 12411|\n",
      "|  Kris| 22|         3| 12000|\n",
      "|Adarsh| 22|         4| 81000|\n",
      "| Anand| 44|        12| 10101|\n",
      "| Karan| 43|         2| 12243|\n",
      "| Kunal| 21|         4|  8425|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84225e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| Name|Age|Experience|Salary|\n",
      "+-----+---+----------+------+\n",
      "|Kunal| 21|         4|  8425|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### selecting/filtering the people who has less or equal to 10K salary\n",
    "\n",
    "df.filter(\"Salary <= 10000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eda5466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| Name|Age|\n",
      "+-----+---+\n",
      "|Kunal| 21|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"Salary <= 10000\").select(['Name','Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7ea9f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| Name|Age|Experience|Salary|\n",
      "+-----+---+----------+------+\n",
      "|Kunal| 21|         4|  8425|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"Salary\"] <= 10000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9f76b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+------+\n",
      "| Name|Age|Experience|Salary|\n",
      "+-----+---+----------+------+\n",
      "| Shri| 29|         2| 12411|\n",
      "| Kris| 22|         3| 12000|\n",
      "|Anand| 44|        12| 10101|\n",
      "|Karan| 43|         2| 12243|\n",
      "+-----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df[\"Salary\"] >= 10000) & \n",
    "        (df[\"Salary\"] <= 30000) ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f758de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+------+\n",
      "|  Name|Age|Experience|Salary|\n",
      "+------+---+----------+------+\n",
      "|Adarsh| 22|         4| 81000|\n",
      "+------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(~(df[\"Salary\"] <= 20000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd995c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
