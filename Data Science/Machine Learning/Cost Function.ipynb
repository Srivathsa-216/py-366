{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83c85820",
   "metadata": {},
   "source": [
    "Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f6702ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " m 3.1, b 0.9, cost 89.0, iteration 0\n",
      " m 2.52, b 0.78, cost 3.8599999999999994, iteration 1\n",
      " m 2.6140000000000003, b 0.8460000000000001, cost 0.9763999999999999, iteration 2\n",
      " m 2.5848, b 0.8772, cost 0.8513360000000004, iteration 3\n",
      " m 2.57836, b 0.91404, cost 0.81970064, iteration 4\n",
      " m 2.567952, b 0.949128, cost 0.7921173536, iteration 5\n",
      " m 2.5584664, b 0.9838296, cost 0.7655590528640001, iteration 6\n",
      " m 2.54900448, b 1.01790672, cost 0.7398944506073604, iteration 7\n",
      " m 2.539727536, b 1.0514147040000001, cost 0.7150903372945663, iteration 8\n",
      " m 2.5306028352, b 1.0843549728000001, cost 0.6911177570948888, iteration 9\n",
      " m 2.52163322464, b 1.1167386249600002, cost 0.667948830166544, iteration 10\n",
      " m 2.512815090048, b 1.1485747950720002, cost 0.6455566148366696, iteration 11\n",
      " m 2.5041460524735997, b 1.1798727885504001, cost 0.6239150727392739, iteration 12\n",
      " m 2.49562355818752, b 1.2106416939532803, cost 0.602999038418565, iteration 13\n",
      " m 2.487245135995264, b 1.2408904571016963, cost 0.5827841900618126, iteration 14\n",
      " m 2.479008349269965, b 1.2706278705929475, cost 0.5632470212170514, iteration 15\n",
      " m 2.4709108038951193, b 1.2998625787526632, cost 0.5443648134590486, iteration 16\n",
      " m 2.4629501459846894, b 1.328603079708861, cost 0.5261156099716162, iteration 17\n",
      " m 2.4551240614888727, b 1.3568577279425682, cost 0.508478190015543, iteration 18\n",
      " m 2.447430275468342, b 1.3846347367016496, cost 0.4914320442524625, iteration 19\n",
      " m 2.439866551442671, b 1.411942180390982, cost 0.4749573508959591, iteration 20\n",
      " m 2.432430690738438, b 1.4387879969190824, cost 0.4590349526621794, iteration 21\n",
      " m 2.4251205318504314, b 1.4651799900056428, cost 0.4436463344931504, iteration 22\n",
      " m 2.417933949813264, b 1.4911258314499491, cost 0.42877360202689574, iteration 23\n",
      " m 2.410868855583689, b 1.516633063360975, cost 0.41439946078931755, iteration 24\n",
      " m 2.403923195433338, b 1.5417091003497707, cost 0.40050719608364665, iteration 25\n",
      " m 2.397094950351735, b 1.5663612316847921, cost 0.38708065355407184, iteration 26\n",
      " m 2.390382135459389, b 1.5905966234107924, cost 0.3741042204009627, iteration 27\n",
      " m 2.3837827994308234, b 1.6144223204318966, cost 0.36156280722581025, iteration 28\n",
      " m 2.3772950239273487, b 1.63784524855946, cost 0.3494418304848192, iteration 29\n",
      " m 2.3709169230394274, b 1.6608722165253094, cost 0.33772719553070274, iteration 30\n",
      " m 2.3646466427384647, b 1.6835099179609503, cost 0.32640528022299464, iteration 31\n",
      " m 2.3584823603378684, b 1.7057649333433158, cost 0.31546291908779983, iteration 32\n",
      " m 2.3524222839632185, b 1.7276437319076237, cost 0.30488738800857484, iteration 33\n",
      " m 2.346464652031391, b 1.7491526735278957, cost 0.29466638943012996, iteration 34\n",
      " m 2.3406077327384924, b 1.7702980105656887, cost 0.2847880380586522, iteration 35\n",
      " m 2.334849823556444, b 1.791085889687572, cost 0.275240847041116, iteration 36\n",
      " m 2.329189250738084, b 1.8115223536518816, cost 0.26601371460801604, iteration 37\n",
      " m 2.323624368830627, b 1.8316133430652684, cost 0.2570959111638838, iteration 38\n",
      " m 2.318153560197357, b 1.8513646981095535, cost 0.2484770668105837, iteration 39\n",
      " m 2.312775234547398, b 1.870782160239391, cost 0.2401471592888743, iteration 40\n",
      " m 2.307487828473443, b 1.8898713738512325, cost 0.23209650232421133, iteration 41\n",
      " m 2.302289804997286, b 1.9086378879240764, cost 0.2243157343632518, iteration 42\n",
      " m 2.2971796531230484, b 1.9270871576324828, cost 0.21679580768794726, iteration 43\n",
      " m 2.2921558873979504, b 1.94522454593232, cost 0.20952797789457814, iteration 44\n",
      " m 2.287217047480509, b 1.963055325119703, cost 0.2025037937254882, iteration 45\n",
      " m 2.282361697716038, b 1.9805846783635799, cost 0.19571508724170383, iteration 46\n",
      " m 2.2775884267193223, b 1.9978177012124105, cost 0.1891539643249979, iteration 47\n",
      " m 2.2728958469643445, b 2.014759403075373, cost 0.18281279549836707, iteration 48\n",
      " m 2.2682825943809535, b 2.031414708678532, cost 0.1766842070542369, iteration 49\n",
      " m 2.263747327958345, b 2.047788459496393, cost 0.17076107248009, iteration 50\n",
      " m 2.2592887293552475, b 2.0638854151592505, cost 0.16503650417153282, iteration 51\n",
      " m 2.2549055025167, b 2.079710254836751, cost 0.1595038454231776, iteration 52\n",
      " m 2.2505963732973044, b 2.095267578598066, cost 0.1541566626880198, iteration 53\n",
      " m 2.24636008909085, b 2.110561908749068, cost 0.14898873809630875, iteration 54\n",
      " m 2.2421954184661947, b 2.1255976911469063, cost 0.14399406222521696, iteration 55\n",
      " m 2.2381011508093085, b 2.140379296492357, cost 0.13916682711089676, iteration 56\n",
      " m 2.234076095971362, b 2.154911021600329, cost 0.13450141949479977, iteration 57\n",
      " m 2.230119083922765, b 2.1691970906488875, cost 0.12999241429640668, iteration 58\n",
      " m 2.2262289644130573, b 2.1832416564071693, cost 0.12563456830477537, iteration 59\n",
      " m 2.2224046066365437, b 2.197048801442535, cost 0.12142281408157163, iteration 60\n",
      " m 2.218644898903585, b 2.2106225393073187, cost 0.11735225406849686, iteration 61\n",
      " m 2.214948748317446, b 2.223966815705511, cost 0.11341815489225414, iteration 62\n",
      " m 2.2113150804566017, b 2.237085509639726, cost 0.10961594186043476, iteration 63\n",
      " m 2.207742839062422, b 2.2499824345387727, cost 0.10594119364192585, iteration 64\n",
      " m 2.204230985732126, b 2.262661339366169, cost 0.1023896371256476, iteration 65\n",
      " m 2.200778499616937, b 2.275125909709914, cost 0.09895714245164931, iteration 66\n",
      " m 2.197384377125332, b 2.2873797688538415, cost 0.09563971820877826, iteration 67\n",
      " m 2.1940476316313147, b 2.299426478830858, cost 0.09243350679334461, iteration 68\n",
      " m 2.190767293187611, b 2.311269541458378, cost 0.08933477992338035, iteration 69\n",
      " m 2.187542408243725, b 2.3229123993562566, cost 0.08633993430327605, iteration 70\n",
      " m 2.1843720393687502, b 2.334358436947513, cost 0.08344548743375868, iteration 71\n",
      " m 2.181255264978871, b 2.3456109814421366, cost 0.08064807356233224, iteration 72\n",
      " m 2.1781911790694717, b 2.3566733038042615, cost 0.07794443976947857, iteration 73\n",
      " m 2.175178890951774, b 2.367548619702994, cost 0.0753314421860593, iteration 74\n",
      " m 2.1722175249939246, b 2.3782400904471626, cost 0.07280604233752795, iteration 75\n",
      " m 2.1693062203664586, b 2.3887508239042687, cost 0.07036530361069966, iteration 76\n",
      " m 2.1664441307920734, b 2.399083875403904, cost 0.06800638783896373, iteration 77\n",
      " m 2.1636304242996216, b 2.4092422486258918, cost 0.0657265520019769, iteration 78\n",
      " m 2.16086428298227, b 2.419228896473416, cost 0.06352314503599484, iteration 79\n",
      " m 2.1581449027597484, b 2.4290467219313934, cost 0.0613936047511307, iteration 80\n",
      " m 2.155471493144607, b 2.4386985789103295, cost 0.05933545485196432, iteration 81\n",
      " m 2.1528432770124404, b 2.4481872730759147, cost 0.057346302058027765, iteration 82\n",
      " m 2.1502594903759817, b 2.4575155626645913, cost 0.05542383332082406, iteration 83\n",
      " m 2.1477193821630243, b 2.4666861592853375, cost 0.053565813134143936, iteration 84\n",
      " m 2.145222213998096, b 2.4757017287078966, cost 0.05177008093454941, iteration 85\n",
      " m 2.1427672599878216, b 2.484564891637678, cost 0.05003454858900295, iteration 86\n",
      " m 2.1403538065099146, b 2.4932782244775638, cost 0.04835719796672347, iteration 87\n",
      " m 2.1379811520057395, b 2.501844260076833, cost 0.04673607859243991, iteration 88\n",
      " m 2.135648606776376, b 2.510265488467428, cost 0.04516930537831803, iteration 89\n",
      " m 2.133355492782134, b 2.518544357587772, cost 0.043655056431923134, iteration 90\n",
      " m 2.131101143445455, b 2.526683273994355, cost 0.04219157093766536, iteration 91\n",
      " m 2.128884903457148, b 2.534684603561283, cost 0.040777147109271154, iteration 92\n",
      " m 2.1267061285859, b 2.5425506721680105, cost 0.039410140210890766, iteration 93\n",
      " m 2.124564185491007, b 2.5502837663754394, cost 0.0380889606445504, iteration 94\n",
      " m 2.122458451538267, b 2.557886134090593, cost 0.03681207210171745, iteration 95\n",
      " m 2.1203883146189955, b 2.5653599852200535, cost 0.035577989776834094, iteration 96\n",
      " m 2.118353172972084, b 2.5727074923123494, cost 0.03438527864073859, iteration 97\n",
      " m 2.1163524350090865, b 2.579930791189489, cost 0.03323255177196899, iteration 98\n",
      " m 2.1143855191422443, b 2.587031981567814, cost 0.03211846874400929, iteration 99\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_descent(x, y):\n",
    "    m_curr = b_curr = 0\n",
    "    iterations = 100\n",
    "    n = len(x)\n",
    "    learning_rate = 0.05\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        y_predicted = m_curr * x + b_curr\n",
    "        cost = ( 1/n ) * sum([val**2 for val in (y - y_predicted)])\n",
    "        md = -(2/n) * sum(x * ( y - y_predicted))\n",
    "        bd = -(2/n) * sum(y - y_predicted)\n",
    "        m_curr = m_curr - learning_rate * md\n",
    "        b_curr = b_curr - learning_rate * bd\n",
    "        \n",
    "        print(\" m {}, b {}, cost {}, iteration {}\".format(m_curr, b_curr, cost, i))\n",
    "\n",
    "\n",
    "x = np.array([1,2,3,4,5])\n",
    "y = np.array([5,7,9,11,13])\n",
    "\n",
    "gradient_descent(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ab225e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
