{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6221213a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2024.5.10-cp311-cp311-win_amd64.whl (268 kB)\n",
      "     -------------------------------------- 269.0/269.0 kB 3.3 MB/s eta 0:00:00\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.3/78.3 kB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: tqdm, regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2024.5.10 tqdm-4.66.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269416b6",
   "metadata": {},
   "source": [
    "        NLTK (Natural Language Toolkit) is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources, such as WordNet, along with a suite of text processing libraries for tokenization, stemming, tagging, parsing, and semantic reasoning. NLTK is widely used in academia and industry for tasks such as text classification, sentiment analysis, machine translation, and more, due to its extensive functionality and robustness.\n",
    "\n",
    "    On the other hand, spaCy is a modern natural language processing (NLP) library designed for efficient and production-ready processing of large volumes of text. It provides pre-trained models for various NLP tasks, including tokenization, part-of-speech tagging, named entity recognition, dependency parsing, and more, all of which are optimized for speed and accuracy. Compared to NLTK, spaCy is known for its speed, memory efficiency, and ease of use, making it a popular choice for building scalable and high-performance NLP applications in industry settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c2dda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"\n",
    "NLTK (Natural Language Toolkit) is a leading platform for building Python programs to work with \n",
    "human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources,\n",
    "such as WordNet, along with a suite of text processing libraries for tokenization, stemming, tagging,\n",
    "parsing, and semantic reasoning. NLTK is widely used in academia and industry for tasks such as text classification,\n",
    "sentiment analysis, machine translation, and more, due to its extensive functionality and robustness.\n",
    "\"\"\"   ### corpus means Paragraph in NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c45e2fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNLTK (Natural Language Toolkit) is a leading platform for building Python programs to work with \\nhuman language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources,\\nsuch as WordNet, along with a suite of text processing libraries for tokenization, stemming, tagging,\\nparsing, and semantic reasoning. NLTK is widely used in academia and industry for tasks such as text classification,\\nsentiment analysis, machine translation, and more, due to its extensive functionality and robustness.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "444a0d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NLTK (Natural Language Toolkit) is a leading platform for building Python programs to work with \n",
      "human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources,\n",
      "such as WordNet, along with a suite of text processing libraries for tokenization, stemming, tagging,\n",
      "parsing, and semantic reasoning. NLTK is widely used in academia and industry for tasks such as text classification,\n",
      "sentiment analysis, machine translation, and more, due to its extensive functionality and robustness.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9e9831f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba602d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenization \n",
    "\n",
    "## paragraph --> sentences \n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "documents = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cde4d6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nNLTK (Natural Language Toolkit) is a leading platform for building Python programs to work with \\nhuman language data.',\n",
       " 'It provides easy-to-use interfaces to over 50 corpora and lexical resources,\\nsuch as WordNet, along with a suite of text processing libraries for tokenization, stemming, tagging,\\nparsing, and semantic reasoning.',\n",
       " 'NLTK is widely used in academia and industry for tasks such as text classification,\\nsentiment analysis, machine translation, and more, due to its extensive functionality and robustness.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c01b284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05ec3bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NLTK (Natural Language Toolkit) is a leading platform for building Python programs to work with \n",
      "human language data.\n",
      "It provides easy-to-use interfaces to over 50 corpora and lexical resources,\n",
      "such as WordNet, along with a suite of text processing libraries for tokenization, stemming, tagging,\n",
      "parsing, and semantic reasoning.\n",
      "NLTK is widely used in academia and industry for tasks such as text classification,\n",
      "sentiment analysis, machine translation, and more, due to its extensive functionality and robustness.\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a834748",
   "metadata": {},
   "outputs": [],
   "source": [
    "### tokenisation\n",
    "\n",
    "## para --> words\n",
    "## sentence --> words\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2f87940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLTK',\n",
       " '(',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Toolkit',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'leading',\n",
       " 'platform',\n",
       " 'for',\n",
       " 'building',\n",
       " 'Python',\n",
       " 'programs',\n",
       " 'to',\n",
       " 'work',\n",
       " 'with',\n",
       " 'human',\n",
       " 'language',\n",
       " 'data',\n",
       " '.',\n",
       " 'It',\n",
       " 'provides',\n",
       " 'easy-to-use',\n",
       " 'interfaces',\n",
       " 'to',\n",
       " 'over',\n",
       " '50',\n",
       " 'corpora',\n",
       " 'and',\n",
       " 'lexical',\n",
       " 'resources',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'WordNet',\n",
       " ',',\n",
       " 'along',\n",
       " 'with',\n",
       " 'a',\n",
       " 'suite',\n",
       " 'of',\n",
       " 'text',\n",
       " 'processing',\n",
       " 'libraries',\n",
       " 'for',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'stemming',\n",
       " ',',\n",
       " 'tagging',\n",
       " ',',\n",
       " 'parsing',\n",
       " ',',\n",
       " 'and',\n",
       " 'semantic',\n",
       " 'reasoning',\n",
       " '.',\n",
       " 'NLTK',\n",
       " 'is',\n",
       " 'widely',\n",
       " 'used',\n",
       " 'in',\n",
       " 'academia',\n",
       " 'and',\n",
       " 'industry',\n",
       " 'for',\n",
       " 'tasks',\n",
       " 'such',\n",
       " 'as',\n",
       " 'text',\n",
       " 'classification',\n",
       " ',',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'machine',\n",
       " 'translation',\n",
       " ',',\n",
       " 'and',\n",
       " 'more',\n",
       " ',',\n",
       " 'due',\n",
       " 'to',\n",
       " 'its',\n",
       " 'extensive',\n",
       " 'functionality',\n",
       " 'and',\n",
       " 'robustness',\n",
       " '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e8226a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5256df69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0b76858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_words =[]\n",
    "for sentence in documents:\n",
    "    words_from_sentence = word_tokenize(sentence)\n",
    "    s_words += words_from_sentence\n",
    "    \n",
    "len(s_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b70839",
   "metadata": {},
   "source": [
    "We can observe its the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f7295d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLTK',\n",
       " '(',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Toolkit',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'leading',\n",
       " 'platform',\n",
       " 'for',\n",
       " 'building',\n",
       " 'Python',\n",
       " 'programs',\n",
       " 'to',\n",
       " 'work',\n",
       " 'with',\n",
       " 'human',\n",
       " 'language',\n",
       " 'data',\n",
       " '.',\n",
       " 'It',\n",
       " 'provides',\n",
       " 'easy',\n",
       " '-',\n",
       " 'to',\n",
       " '-',\n",
       " 'use',\n",
       " 'interfaces',\n",
       " 'to',\n",
       " 'over',\n",
       " '50',\n",
       " 'corpora',\n",
       " 'and',\n",
       " 'lexical',\n",
       " 'resources',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'WordNet',\n",
       " ',',\n",
       " 'along',\n",
       " 'with',\n",
       " 'a',\n",
       " 'suite',\n",
       " 'of',\n",
       " 'text',\n",
       " 'processing',\n",
       " 'libraries',\n",
       " 'for',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'stemming',\n",
       " ',',\n",
       " 'tagging',\n",
       " ',',\n",
       " 'parsing',\n",
       " ',',\n",
       " 'and',\n",
       " 'semantic',\n",
       " 'reasoning',\n",
       " '.',\n",
       " 'NLTK',\n",
       " 'is',\n",
       " 'widely',\n",
       " 'used',\n",
       " 'in',\n",
       " 'academia',\n",
       " 'and',\n",
       " 'industry',\n",
       " 'for',\n",
       " 'tasks',\n",
       " 'such',\n",
       " 'as',\n",
       " 'text',\n",
       " 'classification',\n",
       " ',',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'machine',\n",
       " 'translation',\n",
       " ',',\n",
       " 'and',\n",
       " 'more',\n",
       " ',',\n",
       " 'due',\n",
       " 'to',\n",
       " 'its',\n",
       " 'extensive',\n",
       " 'functionality',\n",
       " 'and',\n",
       " 'robustness',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84453916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordpunct_tokenize(corpus))  # you can clearly see a length difference bcz this even considered the \n",
    "                                    # punctuation as a seperate word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e56d766b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLTK',\n",
       " '(',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Toolkit',\n",
       " ')',\n",
       " 'is',\n",
       " 'a',\n",
       " 'leading',\n",
       " 'platform',\n",
       " 'for',\n",
       " 'building',\n",
       " 'Python',\n",
       " 'programs',\n",
       " 'to',\n",
       " 'work',\n",
       " 'with',\n",
       " 'human',\n",
       " 'language',\n",
       " 'data.',\n",
       " 'It',\n",
       " 'provides',\n",
       " 'easy-to-use',\n",
       " 'interfaces',\n",
       " 'to',\n",
       " 'over',\n",
       " '50',\n",
       " 'corpora',\n",
       " 'and',\n",
       " 'lexical',\n",
       " 'resources',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'WordNet',\n",
       " ',',\n",
       " 'along',\n",
       " 'with',\n",
       " 'a',\n",
       " 'suite',\n",
       " 'of',\n",
       " 'text',\n",
       " 'processing',\n",
       " 'libraries',\n",
       " 'for',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'stemming',\n",
       " ',',\n",
       " 'tagging',\n",
       " ',',\n",
       " 'parsing',\n",
       " ',',\n",
       " 'and',\n",
       " 'semantic',\n",
       " 'reasoning.',\n",
       " 'NLTK',\n",
       " 'is',\n",
       " 'widely',\n",
       " 'used',\n",
       " 'in',\n",
       " 'academia',\n",
       " 'and',\n",
       " 'industry',\n",
       " 'for',\n",
       " 'tasks',\n",
       " 'such',\n",
       " 'as',\n",
       " 'text',\n",
       " 'classification',\n",
       " ',',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'machine',\n",
       " 'translation',\n",
       " ',',\n",
       " 'and',\n",
       " 'more',\n",
       " ',',\n",
       " 'due',\n",
       " 'to',\n",
       " 'its',\n",
       " 'extensive',\n",
       " 'functionality',\n",
       " 'and',\n",
       " 'robustness',\n",
       " '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "tokenizer.tokenize(corpus)\n",
    "\n",
    "### here we can observe for all words with '.' isnt considered as a seperate word except the last one '.' will be \n",
    "### considerd as a seperate word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eace34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
