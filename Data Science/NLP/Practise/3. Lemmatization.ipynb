{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "676839f6",
   "metadata": {},
   "source": [
    "### <center><b><i>Lemmatization</i></b></center>\n",
    "\n",
    "        Lemmatization is a process used in natural language processing (NLP) to reduce words to their base or dictionary form, known as the lemma. The main objective of lemmatization is to normalize words so that different inflected forms of the same word are treated as the same token.\n",
    "\n",
    "    For example, consider the words \"run,\" \"running,\" and \"ran.\" The lemma for all of these words is \"run.\" By lemmatizing these words, we can treat them as the same token, which can simplify tasks such as text analysis, sentiment analysis, and document classification.\n",
    "\n",
    "    Lemmatization typically involves identifying the base form of a word by removing affixes such as suffixes and prefixes, as well as performing dictionary lookup to map the word to its lemma. Unlike stemming, which simply chops off affixes to derive the root form of a word, lemmatization considers the word's context and part of speech (e.g., noun, verb, adjective) to determine the correct lemma.\n",
    "\n",
    "    For example:\n",
    "\n",
    "        * The lemma of \"running\" (verb) is \"run.\"\n",
    "        * The lemma of \"better\" (adjective) is \"good.\"\n",
    "        * The lemma of \"mice\" (noun) is \"mouse.\"\n",
    "\n",
    "    Lemmatization helps improve the accuracy of text analysis tasks by reducing vocabulary size and grouping together related words. It is commonly used in various NLP applications such as text preprocessing, information retrieval, and machine translation. Libraries like NLTK (Natural Language Toolkit) and spaCy provide lemmatization functionality for use in Python-based NLP projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7534b6",
   "metadata": {},
   "source": [
    "#### 1. Wordnet Lemmatizer\n",
    "\n",
    "        The WordNet Lemmatizer is a lemmatization tool provided by the NLTK (Natural Language Toolkit) library in Python. WordNet is a lexical database of the English language that organizes words into synsets (sets of synonyms) and provides semantic relationships between words.\n",
    "\n",
    "    The WordNet Lemmatizer utilizes WordNet's information to lemmatize words by mapping them to their base or dictionary forms (lemmas). It considers the part of speech (POS) of each word to determine the appropriate lemma.\n",
    "\n",
    "Here's an example of how to use the WordNet Lemmatizer in Python with NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06648774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "568e79d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06f0b05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3edae95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "POS\n",
    "Noun - n\n",
    "verb - v\n",
    "adjective - a\n",
    "adverb - r\n",
    "'''\n",
    "### by default it will take n\n",
    "lemmatizer.lemmatize('going', pos = 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "647b21eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"running\", \"runner\", \"runs\", \"walked\", \"Universal\", \"University\", \"walking\", \"eats\", \"eating\", \"jumped\", \"jumping\", \"swimmer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17aefc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ---> run\n",
      "runner ---> runner\n",
      "runs ---> run\n",
      "walked ---> walk\n",
      "Universal ---> Universal\n",
      "University ---> University\n",
      "walking ---> walk\n",
      "eats ---> eat\n",
      "eating ---> eat\n",
      "jumped ---> jump\n",
      "jumping ---> jump\n",
      "swimmer ---> swimmer\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \" ---> \" + lemmatizer.lemmatize(word , 'v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf1d6c",
   "metadata": {},
   "source": [
    "Lemmatizers are better usefull in Q&A , Chatbots and also in Text summarisation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
