{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02e0480d",
   "metadata": {},
   "source": [
    "<b><i>Stemming</i></b>\n",
    "\n",
    "    Stemming in NLP is the process of reducing words to their root or base form, known as the \"stem.\" It involves removing suffixes and prefixes from words to transform them into their simplest form. For example, the words \"running,\" \"runner,\" and \"runs\" would all be stemmed to \"run.\" Stemming helps in simplifying words to their core meaning, making it easier to analyze text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a55483",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"running\", \"runner\", \"runs\", \"walked\", \"Universal\", \"University\", \"walking\", \"eats\", \"eating\", \"jumped\", \"jumping\", \"swimmer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a69c05c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d771fb39",
   "metadata": {},
   "source": [
    "1. Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8305b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4f6facd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ---> run\n",
      "runner ---> runner\n",
      "runs ---> run\n",
      "walked ---> walk\n",
      "Universal ---> univers\n",
      "University ---> univers\n",
      "walking ---> walk\n",
      "eats ---> eat\n",
      "eating ---> eat\n",
      "jumped ---> jump\n",
      "jumping ---> jump\n",
      "swimmer ---> swimmer\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\" ---> \"+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29633eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cycl'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('cycling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b08b1b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bat'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('Batting')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5a5aca",
   "metadata": {},
   "source": [
    "2. RegexpStemmer Class\n",
    "\n",
    "    The RegexpStemmer class in NLTK is used for stemming words using regular expressions. It allows users to define custom rules for stemming by specifying patterns to match and replace in words. This flexibility enables the stemming process to be tailored to specific linguistic contexts or requirements, making it a powerful tool for text normalization and preprocessing in natural language processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70a888df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dde7cbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "188560fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('ingeating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f204c0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Th'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('Thing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b07af2",
   "metadata": {},
   "source": [
    "3. Snowball Stemmer\n",
    "\n",
    "* The Snowball Stemmer, also known as the Porter2 Stemmer, is an algorithm used for stemming in natural language processing.\n",
    "* It's an improvement over the original Porter Stemmer algorithm, offering better performance and accuracy. The Snowball Stemmer employs a set of rules and algorithms to reduce words to their root or base form, known as the stem, by removing suffixes.\n",
    "* This process helps normalize variations of words, enabling more efficient text processing, search, and analysis in applications like information retrieval, sentiment analysis, and text mining.\n",
    "* It's widely used in various programming languages and libraries, including NLTK (Natural Language Toolkit) in Python, for preprocessing textual data before analysis or machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af006d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbf91f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball_stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6aef7870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running ---> run\n",
      "runner ---> runner\n",
      "runs ---> run\n",
      "walked ---> walk\n",
      "Universal ---> univers\n",
      "University ---> univers\n",
      "walking ---> walk\n",
      "eats ---> eat\n",
      "eating ---> eat\n",
      "jumped ---> jump\n",
      "jumping ---> jump\n",
      "swimmer ---> swimmer\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \" ---> \" +snowball_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb42b2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairli'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### this might wont lead you the difference let me give you some better example\n",
    "\n",
    "stemming.stem(\"fairly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f69c04b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fair'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball_stemmer.stem('fairly')\n",
    "\n",
    "## through this it will be more clear about the difference and optimisation achieved by the snowball stemmer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
