{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Load essential libraries**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "CrW3wGfQN2KV"
      },
      "id": "CrW3wGfQN2KV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "valued-lodging",
      "metadata": {
        "id": "valued-lodging"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('dark_background')\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Check TensorFlow version**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "CZmMj92lN6Yc"
      },
      "id": "CZmMj92lN6Yc"
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "id": "B2VpALYvOBoG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0a99f4c6-470c-467f-e8c2-2e3cd45a0d87"
      },
      "id": "B2VpALYvOBoG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.15.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Load MNIST Data\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "8jG5ivrRX1O-"
      },
      "id": "8jG5ivrRX1O-"
    },
    {
      "cell_type": "code",
      "source": [
        "## Load MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])\n",
        "\n",
        "num_labels = len(np.unique(y_train))\n",
        "num_features = X_train.shape[1]\n",
        "num_samples = X_train.shape[0]\n",
        "\n",
        "# One-hot encode class labels\n",
        "Y_train = tf.keras.utils.to_categorical(y_train)\n",
        "Y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "# Normalize the samples (images)\n",
        "xmax = np.amax(X_train)\n",
        "xmin = np.amin(X_train)\n",
        "X_train = (X_train - xmin) / (xmax - xmin) # all train features turn into a number between 0 and 1\n",
        "X_test = (X_test - xmin)/(xmax - xmin)\n",
        "\n",
        "print('MNIST set')\n",
        "print('---------------------')\n",
        "print('Number of training samples = %d'%(num_samples))\n",
        "print('Number of features = %d'%(num_features))\n",
        "print('Number of output labels = %d'%(num_labels))"
      ],
      "metadata": {
        "id": "qs1J2W_qX0xw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf718c0b-4257-4216-a49c-a3b8c88fd603"
      },
      "id": "qs1J2W_qX0xw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "MNIST set\n",
            "---------------------\n",
            "Number of training samples = 60000\n",
            "Number of features = 784\n",
            "Number of output labels = 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "We will now look at 3 different ways to build custom models using TensorFlow 2:\n",
        "\n",
        "1. model subclassing ([Making new layers and models via subclassing](https://www.tensorflow.org/guide/keras/making_new_layers_and_models_via_subclassing))\n",
        "2. sequential API\n",
        "3. functional API\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "kjk0YnbgGsr8"
      },
      "id": "kjk0YnbgGsr8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Approach-1**: here we build the model by subclassing the Keras $\\texttt{Model}$ class followed by definition of of layers in $\\texttt{__init__}$ and implementation of the model's forward pass in $\\texttt{call()}$.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "MRgFmy-mYgAS"
      },
      "id": "MRgFmy-mYgAS"
    },
    {
      "cell_type": "code",
      "source": [
        "## Define 1-layer (softmax) neural network architecture\n",
        "# Define model\n",
        "class Softmax_Model(tf.keras.models.Model):\n",
        "    def __init__(self):\n",
        "        super(Softmax_Model, self).__init__()\n",
        "        initializer = tf.keras.initializers.RandomUniform(minval=-0.5, maxval=0.5)\n",
        "        self.dense1 = tf.keras.layers.Dense(num_labels, dtype = 'float64',\\\n",
        "                                 bias_initializer = initializer,\\\n",
        "                                 activation = tf.keras.activations.softmax)\n",
        "\n",
        "    # Forward pass for the model\n",
        "    def call(self, inputs):\n",
        "        a = self.dense1(inputs)\n",
        "        return a"
      ],
      "metadata": {
        "id": "Z_u1srfaY1Tc"
      },
      "id": "Z_u1srfaY1Tc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Build model\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "EZyM0MekDtFI"
      },
      "id": "EZyM0MekDtFI"
    },
    {
      "cell_type": "code",
      "source": [
        "## Build model\n",
        "model = Softmax_Model()\n",
        "batch_size = 100 # batch size\n",
        "model.build((batch_size, num_features))"
      ],
      "metadata": {
        "id": "qfPaz4la4xfe"
      },
      "id": "qfPaz4la4xfe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Compile and train the model on the training batches and test on the test set in one shot\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "od-XJBv8DyiL"
      },
      "id": "od-XJBv8DyiL"
    },
    {
      "cell_type": "code",
      "source": [
        "## Compile model\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = 1e-03) # optimizer\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()  # loss function\n",
        "model.compile(optimizer = opt, loss = loss_fn, metrics = ['acc'])\n",
        "\n",
        "# Train model and simultabeously test on the test set\n",
        "model.fit(X_train, Y_train, batch_size = 100,\\\n",
        "          epochs = 10,\\\n",
        "          validation_data = (X_test, Y_test))"
      ],
      "metadata": {
        "id": "eP63ueEF9Ist",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c397a9fa-096d-455e-92ef-eb39c8c5f980"
      },
      "id": "eP63ueEF9Ist",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "600/600 [==============================] - 4s 5ms/step - loss: 0.6472 - acc: 0.8357 - val_loss: 0.3669 - val_acc: 0.9058\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.3500 - acc: 0.9051 - val_loss: 0.3083 - val_acc: 0.9158\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.3117 - acc: 0.9143 - val_loss: 0.2921 - val_acc: 0.9185\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2938 - acc: 0.9184 - val_loss: 0.2812 - val_acc: 0.9220\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2832 - acc: 0.9217 - val_loss: 0.2766 - val_acc: 0.9217\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2758 - acc: 0.9235 - val_loss: 0.2712 - val_acc: 0.9245\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.2703 - acc: 0.9250 - val_loss: 0.2679 - val_acc: 0.9238\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2660 - acc: 0.9260 - val_loss: 0.2674 - val_acc: 0.9268\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2626 - acc: 0.9272 - val_loss: 0.2660 - val_acc: 0.9264\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2597 - acc: 0.9278 - val_loss: 0.2636 - val_acc: 0.9278\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79b69e66b970>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Instead of doing the above, we can explicitly write down the optimization step using $\\texttt{GradientTape()}$ and train the model\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "k0H0scBfV3wH"
      },
      "id": "k0H0scBfV3wH"
    },
    {
      "cell_type": "code",
      "source": [
        "## Create source dataset from input data (this is helpful for ppipelining later)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
        "batch_size = 100 # batch size\n",
        "# Create training batches\n",
        "train_dataset = train_dataset.shuffle(buffer_size = 1024).batch(batch_size)"
      ],
      "metadata": {
        "id": "SW3BgQ3EW56s"
      },
      "id": "SW3BgQ3EW56s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create softmax model\n",
        "model = Softmax_Model()\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = 1e-03) # optimizer\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()  # loss function\n",
        "\n",
        "# Varible to store training loss per epoch\n",
        "loss_train_epoch = tf.keras.metrics.Mean()\n",
        "\n",
        "# Iterate over epochs\n",
        "nepochs = 10\n",
        "for epoch in range(nepochs):\n",
        "  # Iterate over the batches of the dataset.\n",
        "  for step, train_batch in enumerate(train_dataset):\n",
        "    with tf.GradientTape() as g:\n",
        "      # Compute loss\n",
        "      yhat = model(train_batch[0])\n",
        "      loss = loss_fn(train_batch[1], yhat)\n",
        "\n",
        "    # Calculate gradients\n",
        "    grad = g.gradient(loss, model.trainable_weights)\n",
        "\n",
        "    # Update model\n",
        "    opt.apply_gradients(zip(grad, model.trainable_weights))\n",
        "\n",
        "    # Append training loss\n",
        "    loss_train_epoch(loss)\n",
        "  print('Epoch %d: train loss = %f'%(epoch+1, loss_train_epoch.result()))"
      ],
      "metadata": {
        "id": "2eqel_RYgMR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be9464e6-68e0-4618-d65a-967cc242b4ba"
      },
      "id": "2eqel_RYgMR9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train loss = 0.639664\n",
            "Epoch 2: train loss = 0.494852\n",
            "Epoch 3: train loss = 0.434000\n",
            "Epoch 4: train loss = 0.399185\n",
            "Epoch 5: train loss = 0.376163\n",
            "Epoch 6: train loss = 0.359586\n",
            "Epoch 7: train loss = 0.346981\n",
            "Epoch 8: train loss = 0.336987\n",
            "Epoch 9: train loss = 0.328823\n",
            "Epoch 10: train loss = 0.322007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model so it can be evaluated for test set\n",
        "model.compile(optimizer = opt, loss = loss_fn, metrics = ['acc'])\n",
        "print('\\nAccuracy:', model.evaluate(X_test, Y_test, verbose=0)[1])"
      ],
      "metadata": {
        "id": "0zoDASIQs8T4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76daadab-0982-41fc-f160-bcf0d65f2f59"
      },
      "id": "0zoDASIQs8T4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.9259999990463257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Approach-2**: here we build the model using the sequential API of TensorFlow Keras. Try this.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "040kYit81aFc"
      },
      "id": "040kYit81aFc"
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: here we build the model using the sequential API of TensorFlow Keras. Try this.\n",
        "\n",
        "# Define 1-layer (softmax) neural network architecture\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(num_labels, activation='softmax', dtype = 'float64', input_shape=(num_features,))\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = 1e-03) # optimizer\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()  # loss function\n",
        "model.compile(optimizer = opt, loss = loss_fn, metrics = ['acc'])\n",
        "\n",
        "# Train model and simultabeously test on the test set in one shot\n",
        "model.fit(X_train, Y_train, batch_size = 100,\\\n",
        "          epochs = 10,\\\n",
        "          validation_data = (X_test, Y_test))\n"
      ],
      "metadata": {
        "id": "Wmu_m6kl1jci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c384e448-d29e-45a6-f65c-9958a4d3d8b8"
      },
      "id": "Wmu_m6kl1jci",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "600/600 [==============================] - 4s 5ms/step - loss: 0.6330 - acc: 0.8381 - val_loss: 0.3616 - val_acc: 0.9062\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.3458 - acc: 0.9057 - val_loss: 0.3083 - val_acc: 0.9135\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.3090 - acc: 0.9147 - val_loss: 0.2902 - val_acc: 0.9187\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2921 - acc: 0.9188 - val_loss: 0.2803 - val_acc: 0.9215\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2816 - acc: 0.9214 - val_loss: 0.2743 - val_acc: 0.9239\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.2744 - acc: 0.9234 - val_loss: 0.2737 - val_acc: 0.9230\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.2690 - acc: 0.9248 - val_loss: 0.2725 - val_acc: 0.9233\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2653 - acc: 0.9257 - val_loss: 0.2668 - val_acc: 0.9255\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.2620 - acc: 0.9269 - val_loss: 0.2657 - val_acc: 0.9263\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2592 - acc: 0.9280 - val_loss: 0.2680 - val_acc: 0.9255\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79b6781cfdc0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Approach-3**: here we build the model using the functional API of TensorFlow Keras. Try this.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Ljcm4VTm1j9f"
      },
      "id": "Ljcm4VTm1j9f"
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: here we build the model using the functional API of TensorFlow Keras. Try this.\n",
        "\n",
        "# Define input layer\n",
        "input = tf.keras.Input(shape=(num_features,))\n",
        "# Define Dense layer\n",
        "dense = tf.keras.layers.Dense(num_labels, activation='softmax', dtype = 'float64')\n",
        "# Connect input layer to dense layer\n",
        "yhat = dense(input)\n",
        "\n",
        "# Define model\n",
        "model = tf.keras.Model(input, yhat)\n",
        "\n",
        "# Compile model\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = 1e-03) # optimizer\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()  # loss function\n",
        "model.compile(optimizer = opt, loss = loss_fn, metrics = ['acc'])\n",
        "\n",
        "# Train model and simultabeously test on the test set in one shot\n",
        "model.fit(X_train, Y_train, batch_size = 100,\\\n",
        "          epochs = 10,\\\n",
        "          validation_data = (X_test, Y_test))\n"
      ],
      "metadata": {
        "id": "MMVOs9Jk1noX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9d31f5d-68bb-401c-caa6-61df8b8b288a"
      },
      "id": "MMVOs9Jk1noX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.6296 - acc: 0.8427 - val_loss: 0.3654 - val_acc: 0.9038\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.3473 - acc: 0.9055 - val_loss: 0.3105 - val_acc: 0.9152\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.3098 - acc: 0.9144 - val_loss: 0.2896 - val_acc: 0.9186\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.2922 - acc: 0.9180 - val_loss: 0.2795 - val_acc: 0.9239\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.2821 - acc: 0.9209 - val_loss: 0.2748 - val_acc: 0.9237\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2750 - acc: 0.9227 - val_loss: 0.2706 - val_acc: 0.9247\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2699 - acc: 0.9246 - val_loss: 0.2681 - val_acc: 0.9257\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2657 - acc: 0.9261 - val_loss: 0.2679 - val_acc: 0.9254\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.2623 - acc: 0.9273 - val_loss: 0.2654 - val_acc: 0.9267\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.2593 - acc: 0.9285 - val_loss: 0.2639 - val_acc: 0.9270\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79b679a03b20>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}